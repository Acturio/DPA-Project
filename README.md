<table>
	<tr>
		<td style="text-aling: center; font-weight: bold; font-size: 24px">üü¢ Maestr√≠a en Ciencia de Datos</td>
		<td rowspan="3"><p align = "right"><img src="results/img/itam_logo.png" width="390" height="170"></p></td>
	</tr>
	<tr>
		<td style="text-aling: center; font-weight: bold; font-size: 20px">:red_circle: M√©todos de Gran Escala</td>
	</tr>
		<td>
			<table>
				<tr><td style="font-weight: bold;">:black_circle: Colaboradores</td></tr>
				<tr><td>Karina Lizette Gamboa Puente</td></tr>
				<tr><td>Oscar Arturo Bringas L√≥pez</td></tr>
				<tr><td>Aide Jazm√≠n Gonz√°lez Cruz</td></tr>
				<tr><td>Miguel L√≥pez Cruz</td></tr>
				<tr>
			</table>
		</td>
	</tr>
</table>

# DPA-Project: Food Inspections :pizza: :hamburger: :coffee: :rice_cracker: :poultry_leg: :bento: :ramen:

## :large_blue_circle: Tabla de contenido

1. [Introducci√≥n](https://github.com/Acturio/DPA-Project/blob/main/README.md#introducci%C3%B3n-clipboard) :clipboard:
2. [Informaci√≥n general](https://github.com/Acturio/DPA-Project/blob/main/README.md#informaci%C3%B3n-general-bookmark_tabs) :bookmark_tabs:
3. [Requerimientos de infraestructura](https://github.com/Acturio/DPA-Project/blob/main/README.md#requerimientos-de-infraestructura-computer) :computer:
4. [Instalaci√≥n](https://github.com/Acturio/DPA-Project/blob/main/README.md#instalaci%C3%B3n-minidisc) :minidisc:
5. [Organizaci√≥n del c√≥digo](https://github.com/Acturio/DPA-Project/blob/main/README.md#organizaci%C3%B3n-del-c%C3%B3digo-octocat) :octocat:
6. [Correr el pipeline](https://github.com/Acturio/DPA-Project/blob/main/README.md#correr_el_pipeline-green_circle) :green_circle:
7. [Sesgo e inequidad](https://github.com/Acturio/DPA-Project/blob/main/README.md#sesgo_e_inequidad-bar_chart) :bar_chart:

## Introducci√≥n :clipboard:

Este proyecto esta enfocado a realizar una predicci√≥n de los establecimientos de comida en la Ciudad de Chicago que tengan m√°s probabilidad de cometer una violaci√≥n y por lo tanto se les har√° una inspecci√≥n, de esta manera se priorizar√°n las visitas a estos establecimientos.

## Informaci√≥n general :bookmark_tabs:

A continuaci√≥n se presenta un res√∫men de los datos con los cuales se trabajar√°:

- N√∫mero de registros: **215K**
- N√∫mero de columnas: **17**
- Diccionario de datos:

| Variable | Tipo  | Descripci√≥n |
| :------- | :----:| :---------: |
|Inspection ID|Number|Identificador de la inspecci√≥n|
|DBA Name|Text|Nombre del establecimiento|
|AKA Name|Text|Alias (tambi√©n conocido como)|
|License #|Number|N√∫mero de licencia del establecimiento|
|Facility Type|Text|Tipo de establecimiento|
|Risk|Text|Riesgo de cometer una violaci√≥n|
|Address|Text|Direcci√≥n del establecimiento|
|City|Text|Ciudad donde est√° el establecimiento|
|State|Text|Estado donde se encuentra el establecimiento|
|Zip|Number|C√≥digo postal del establecimiento|
|Inspection Date|Floating Timestamp|Fecha de la inspecci√≥n|
|Inspection Type|Text|Tipo de inspecci√≥n|
|Results|Text|Resultado de la inspecci√≥n|
|Violations|Text|Observaciones de las violaciones encontradas|
|Latitude|Number|Latitud del establecimiento|
|Longitude|Number|Longutud del establecimiento|
|Location|Location|Latitud y Longitud (geopoint)|
    
#### Pregunta anal√≠tica a contestar con el modelo predictivo

Con este proyecto pensamos contestar la siguiente pregunta:

- ¬øEl establecimiento pasar√° o no la inspecci√≥n?

#### Frecuencia de actualizaci√≥n de los datos

- La frecuencia de datos fuente es diaria, sin embargo en en este proyecto se realizar√° semanalmente.

## Requerimientos de infraestructura. :computer:

El presente proyecto se elabora siguiendo una estructura en la nube, usando los servicios de AWS cuyo diagrama se muestra a continuaci√≥n:

![](./results/img/ec2_architecture.png) 


Se accede de manera local desde una PC/Laptop, y el filtro de entrada es nuestra m√°quina de bastion que funciona como cadenero de la infrestructura en la nube, y este por medio de SSH permite la conexi√≥n a la maquina EC2 que es la que contiene el c√≥digo del proyecto y  tiene comunicaci√≥n con la RDS.


## Instalaci√≥n :minidisc:

### Requerimientos

1. **Clonar el repositorio**

- Para comenzar deber√° [instalar la librer√≠a de git](https://github.com/git-guides/install-git), para ello puede seguirlos pasos descritos en esta p√°gina.

- Clonar el repositorio en la m√°quina EC2.

```
git clone https://github.com/Acturio/DPA-Project
```

2. **Ambiente virtual**

- Deber√° instalar [pyenv](https://github.com/pyenv/pyenv), para configurar un ambiente virtual [pyenv-virtualenv](https://github.com/pyenv/pyenv-virtualenv) con python superior o igual a 3.7.4., al cual podra acceder con el siguiente comando como ejemplo: 

```
pyenv activate nombre_de_tu_ambiente
```

3. **Librer√≠as**

- Una vez dentro del abiente instalar los paquetes descritos en el archivo requirements.txt con el siguiente comando:

```
pip install -r requirements.txt
```

4. **Credenciales**


Se necesitan obtener los siguientes recursos de conexi√≥n:

- Obtener token de la `API de Food inspections`, para ello de clic [aqu√≠](https://data.cityofchicago.org/profile/edit/developer_settings)

- Se debe contar con credenciales de AWS (Access key ID y Secret access key) dados por el administrador de la infraestructura en AWS, y guardarlos en un archivo `credentials.yaml`. El archivo con las credenciales debe estar en la carpeta `conf/local/credentials.yaml` y deber√° estar en la lista de `git ignore` para que sus datos esten seguros. La estructura del archivo `credentials.yaml` debe tener una estructura como la que se presenta a continuaci√≥n:


```
---
s3:
   aws_access_key_id: "TU_ACCESS_KEY_ID"
   aws_secret_access_key: "SECRET_ACCESS_KEY"
   
food_inspections: 
   api_token: "TU_TOKEN" 
   
db:
  user: "usuario_db"
  pass: "password_db"
  host: "host_rds"
  port: "puerto"
  database: "nombre_db"

```

- Para la conexi√≥n a la base de datos como servicio se necesita un archivo `.pg_service.conf` alojado en la m√°quina EC2 con la siguiente estructura

```
# Conexi√≥n RDS
[db_service]
host=host_rds
port=puerto
user=usuario_db
dbname=nombre_db
password=password_db 
```


Y se deber√° ejecutar lo siguiente para guadarlo en las variables globales (en este ejemplo guardamos el archivo `.pg_service.conf` en `home`)

```
export PGSERVICEFILE=${HOME}/.pg_service.conf   
export PGSERVICE=db_service
```

De esta manera se puede conectar a la base de postgresql corriendo el siguiente comando:

```
psql service=db_service
```

Para crear el squema de metadata se corre el siguiente query 

```
psql service=db_service -f ruta_repositoro/sql/create_metadata.sql
```

## Organizaci√≥n del c√≥digo :octocat:

El repositorio se encuentra organizado de la siguiente manera:

```
‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
‚îú‚îÄ‚îÄ conf
‚îÇ   ‚îú‚îÄ‚îÄ base           <- Space for shared configurations like parameters
‚îÇ   ‚îî‚îÄ‚îÄ local          <- Space for local configurations, usually credentials
‚îÇ
‚îú‚îÄ‚îÄ docs               <- Space for Sphinx documentation
‚îÇ
‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks.
‚îÇ
‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
‚îÇ
‚îú‚îÄ‚îÄ results            <- Intermediate analysis as HTML, PDF, LaTeX, etc.
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file
‚îÇ
‚îú‚îÄ‚îÄ .gitignore         <- Avoids uploading data, credentials, outputs, system files etc
‚îÇ
‚îú‚îÄ‚îÄ infrastructure
‚îú‚îÄ‚îÄ sql
‚îú‚îÄ‚îÄ setup.py
‚îî‚îÄ‚îÄ src                <- Source code for use in this project.
    ‚îú‚îÄ‚îÄ __init__.py    <- Makes src a Python module
    ‚îÇ
    ‚îú‚îÄ‚îÄ utils      <- Functions used across the project
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ etl       <- Scripts to transform data from raw to intermediate
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ pipeline

```


## Correr el pipeline :green_circle:

- Se deber√° configurar un ***Foxy-Proxy*** para que tu browser pueda mostrar contenido de los web services que ocuparemos en el EMR. Para ello deber√°s seguir las [instrucciones](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-connect-master-node-proxy.html) en este tutoria, ya que dependiendo del navegador que se tenga los pasos de configuraci√≥n son diferentes, adem√°s es recomendable hacerlo sobre `Chrome` ya que es el navegador con m√°s compatibilidad con la funci√≥nque se busca.


- Desde la EC2 podr√° ejecutar el siguiente pipele, es importante ubicarse en la ra√≠z del proyecto


- Deber√° ingresar a la m√°quina de bastion desde su m√°quina en el comando.

```
ssh -i llave_publica_aws usuario@host_bastion
```

- Una vez en bastion deber√° conectarse a la EC2

```
ssh -i llave_publica_aws usuario@host_ec2
```

Como sugerencia le recomendmos abrir 3 terminales con los 2 procedimientos decritos previamente.

- En la primera ventana ejecutamos `luigid` dentro de nuestro ambiente virtual, esto nos permitir√° acceder al servicio de `Foxy-Proxy` que se configur√≥ en el inicio de este apartado, y sirve para habilitar el scheduler en nuestro navegador local ingresado la direcci√≥n `http:\\localhost:8082`.

- La segunda ventana nos servir√° para ejecutar el pipeline, el cu√°l debe correr con la siguiente estructura:


```
PYTHONPATH='.' luigi \
--module src.pipeline.LuigiModelSelectionMetadataTask ModelSelectionMetadataTask \
--path-cred ./conf/local/credentials.yaml \
--initial false \
--limit 2000 \
--date '2021-04-16' \
--exercise true \
--local-scheduler
```

Descripci√≥n:

***-- module*** se especifica el modulo a cargar, seguido del nombre de la tarea.

***--local-scheduler*** con esta opci√≥n no se muestra el resultado en el `Central Scheduler`, para reflejar el resultado en el este se debe omitir esta opci√≥n.

***--path-cred*** se indica la ruta del archivo que contiene las credenciales, en este caso se encuentra en `./conf/local/credentials.yaml`, recuerde que debe contar con su archivo `credentials.yaml` en la carpeta `conf/local/`

***--initial*** con esta bandera en `true` indica que se har√° una ingesta inicial (hist√≥rica). En caso de una ingesta consecutiva deber√° ir en `false`

***--limit*** esta bandera indica el limite de datos, para la ingesta hist√≥rica se sugiere vaya en *300000*, el cual es el dato por default, para este ejemplo se a colocado el valor de 100.

***--date*** con esta la bandera se indica desde que fecha se requiere la ingesta inicial. **Nota:** En caso de que se le pase como par√°metro una fecha mayor al d√≠a de hoy, el pipeline fallar√° e indicar√° que no se permiten este tipo de fechas.

***--exercise*** con esta bandera se le indica si toma una muestra con `true` y si es `false` toma todos los datos.

- Para una **ingesta consecutiva** se corre la siguiente secuencia de comandos, de acuerdo a las opciones descritas anteriormente.




- Finalmente la tercera ventana nos servir√° para mantener la conexi√≥n a la base de datos para supervisar la carga de datos. Para ello usaremos la l√≠nea de comando descrita en la parte de conexiones.

```
psql service=db_service
```
 y se podr√°n ejecutar los `selects` a las tablas de metadata para observar los datos insertados
 
```
SELECT * FROM metadata.ingestion;
SELECT * FROM metadata.almacenamiento;
SELECT * FROM metadata.cleaning;
SELECT * FROM metadata.feature;
SELECT * FROM metadata.entrenamiento;
SELECT * FROM metadata.seleccion;
SELECT * FROM metadata.bias_fairness;
```

y para los `test`

```
SELECT * FROM metadata.test_ingestion;
SELECT * FROM metadata.test_almacenamiento;
SELECT * FROM metadata.test_cleaning;
SELECT * FROM metadata.test_feature;
SELECT * FROM metadata.test_entrenamiento;
SELECT * FROM metadata.test_seleccion;
SELECT * FROM metadata.test_bias_fairness;
```

la tabla de seguimiento de los `tasks` que corre luigi los podr√° consultar con:

```
SELECT * FROM public.table_updates;
```

- Una vez ejecutados correctamente las tareas, podr√° verificar que sus archivos se encuentran en `AWS` en el bucket especificado y en la ruta `ingestion/initial/` para cargas iniciales y en la ruta `ingestion/consecutive/` para cargas consecutivas.

- As√≠ mismo verificar el estatus de las tareas en `http:\\localhost:8082` en el `Central Scheduler` de `luigi`, siempre y cuando haya omitido la opci√≥n `--local-schedule` a la hora de ejecutar los comandos. 

- Si todo fue correcto, observar√° la siguiente salida:

![](./results/img/checkpoint6_1.png) 



![](./results/img/checkpoint6_2.png) 


## Sesgo e inequidad :bar_chart:

En este proyecto estamos considerando como variable protegida el tipo de inspecci√≥n, de la base original (hist√≥rica) se pueden cuantificar 96 disintos tipos de inspecci√≥n, sin embargo se creo una nueva variable (`type_inspection_limpia`) que agrupa estas s√≥lo 10 tipos:

- Canvass
- License
- Licuor
- Complaint
- Reinspection
- Ilegal
- Out of bussiness
- Not ready
- Pre license
- Others

Por lo que nuestro atributo protegido es esta variable `type_inspection_limpia`.

El grupo de refrencia es `Canvass`, ya que es la categor√≠a con mayor tama√±o entre todos los grupos existentes, con un 53 % aproximadamente.

<table>
	<tr>
		<td>![](./results/img/group.jpeg)</td>
		<td>![](./results/img/group_p.jpeg)</td>
	</tr>
</table> 

Analizando el proyecto y viendolo desde el punto de vista del usuario (due√±o del establecimiento) llegamos a la conclusi√≥n de que es un modelo *asistivo*, ya que le va a decir si ir√°n o no a inspeccioanr su establecimiento, por tanto podr√° estar preparado.

En este caso al ser un modelo asistivo tenemos que las variables a cuantificar son: `Recall parity`, `FN/GS Parity`, `FOR Parity` y `FNR Parity`, de acuerdo al `Farirness tree`, sin embargo como el modelo afectar√° a una peque√±a fracci√≥n de la poblaci√≥n, s√≥lo nos enfocaremos a medir el ***Recall parity***.


Los resultadados de sesgo e inequidad se guardan en la tabla sesgo.bias_fairness del RDS, se pueden consultar con el `query`:

```
SELECT * FROM sesgo.bias_fairness;
```


